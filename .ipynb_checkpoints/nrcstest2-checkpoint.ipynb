{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import json\n",
    "from geojson import Point, Feature, FeatureCollection, dump\n",
    "from rasterstats import point_query\n",
    "from shapely import geometry as sgeom\n",
    "import ulmo\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "############################ USER INPUTS ################################\n",
    "#########################################################################\n",
    "\n",
    "#path for created shape files\n",
    "OUTpath = '/scratch/ms_shapefiles/'\n",
    "\n",
    "# TIME - note that fetched data will range from 12 am on st_dt to 12 am\n",
    "# on ed_dt\n",
    "# for now, I am only using manual option for a test.  \n",
    "#st_dt = '2022-10-01'\n",
    "#ed_dt = '2022-10-05'\n",
    "\n",
    "#stdt=st_dt\n",
    "#eddt=ed_dt\n",
    "#print(stdt, eddt)\n",
    "\n",
    "# TIME\n",
    "# choose if want to set 'manual' or 'auto' date \n",
    "date_flag = 'manual'\n",
    "# If you choose 'manual' set your dates below  \n",
    "# This will start on the 'begin' date at 0:00 and the last iteration will \n",
    "# be on the day before the 'end' date below.\n",
    "st_dt = '2022-01-01'\n",
    "ed_dt = '2022-01-02'\n",
    "#########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date setup function\n",
    "def set_dates(st_dt,ed_dt,date_flag):\n",
    "    if date_flag == 'auto':\n",
    "        # ###automatically select date based on today's date \n",
    "        hoy = date.today()\n",
    "        antes = timedelta(days = 2)\n",
    "        #start date 2 days before today's date\n",
    "        fecha = hoy - antes\n",
    "        stdt = fecha.strftime(\"%Y-%m-%d\")\n",
    "        antes = timedelta(days = 1)\n",
    "        #end date 1 days before today's date\n",
    "        fecha = hoy - antes\n",
    "        eddt = fecha.strftime(\"%Y-%m-%d\")\n",
    "    elif date_flag == 'manual':\n",
    "        stdt = st_dt\n",
    "        eddt = ed_dt\n",
    "    return stdt, eddt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# SNOTEL Functions\n",
    "#########################################################################\n",
    "\n",
    "# functions to get SNOTEL stations as geodataframe\n",
    "def sites_asgdf(ulmo_getsites, stn_proj):\n",
    "    \"\"\" Convert ulmo.cuahsi.wof.get_sites response into a point GeoDataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Note: Found one SNOTEL site that was missing the location key\n",
    "    sites_df = pd.DataFrame.from_records([\n",
    "        OrderedDict(code=s['code'], \n",
    "        longitude=float(s['location']['longitude']), \n",
    "        latitude=float(s['location']['latitude']), \n",
    "        name=s['name'], \n",
    "        elevation_m=s['elevation_m'])\n",
    "        for _,s in ulmo_getsites.items()\n",
    "        if 'location' in s\n",
    "    ])\n",
    "\n",
    "    sites_gdf = gpd.GeoDataFrame(\n",
    "        sites_df, \n",
    "        geometry=gpd.points_from_xy(sites_df['longitude'], sites_df['latitude']),\n",
    "        crs=stn_proj\n",
    "    )\n",
    "    return sites_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snotel_stns():\n",
    "    \n",
    "    #path to CSO domains\n",
    "    domains_resp = requests.get(\"https://raw.githubusercontent.com/snowmodel-tools/preprocess_python/master/CSO_domains.json\")\n",
    "    domains = domains_resp.json()\n",
    "    \n",
    "    #USA\n",
    "    #Bbox = {\"latmax\": 72, \"latmin\": 18, \"lonmin\": -172, \"lonmax\": -66}\n",
    "    Bbox = {\"latmax\": 44, \"latmin\": 43.5, \"lonmin\": -127, \"lonmax\": -122}\n",
    "    stn_proj = \"epsg:4326\"\n",
    "\n",
    "    # Convert the bounding box dictionary to a shapely Polygon geometry using sgeom.box\n",
    "    box_sgeom = sgeom.box(Bbox['lonmin'], Bbox['latmin'], Bbox['lonmax'], Bbox['latmax'])\n",
    "    box_gdf = gpd.GeoDataFrame(geometry=[box_sgeom], crs=stn_proj)\n",
    "    \n",
    "    # WaterML/WOF WSDL endpoint url \n",
    "    wsdlurl = \"https://hydroportal.cuahsi.org/Snotel/cuahsi_1_1.asmx?WSDL\"\n",
    "    \n",
    "    # get dictionary of snotel sites \n",
    "    sites = ulmo.cuahsi.wof.get_sites(wsdlurl,user_cache=True)\n",
    "\n",
    "    #turn sites to geodataframe \n",
    "    snotel_gdf = sites_asgdf(sites,stn_proj)\n",
    "    \n",
    "    #clip snotel sites to domain bounding box\n",
    "    gdf = gpd.sjoin(snotel_gdf, box_gdf, how=\"inner\")\n",
    "    gdf.drop(columns='index_right', inplace=True)\n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(sitecode, variablecode,start_date, end_date):\n",
    "    #print(sitecode, variablecode,start_date, end_date)\n",
    "    values_df = None\n",
    "    # WaterML/WOF WSDL endpoint url \n",
    "    wsdlurl = \"https://hydroportal.cuahsi.org/Snotel/cuahsi_1_1.asmx?WSDL\"\n",
    "    network = 'SNOTEL:'\n",
    "\n",
    "    try:\n",
    "        #Request data from the server\n",
    "        site_values = ulmo.cuahsi.wof.get_values(\n",
    "            wsdlurl, network+sitecode, variablecode, start=start_date, end=end_date\n",
    "        )\n",
    "        #Convert to a Pandas DataFrame   \n",
    "        values_df = pd.DataFrame.from_dict(site_values['values'])\n",
    "        #Parse the datetime values to Pandas Timestamp objects\n",
    "        values_df['datetime'] = pd.to_datetime(values_df['datetime'])\n",
    "        values_df['Y']=pd.DatetimeIndex(values_df['datetime']).year\n",
    "        values_df['M']=pd.DatetimeIndex(values_df['datetime']).month\n",
    "        values_df['D']=pd.DatetimeIndex(values_df['datetime']).day\n",
    "        #print(values_df)\n",
    "        #Set the DataFrame index to the Timestamps\n",
    "        values_df.set_index('datetime', inplace=True)\n",
    "        #Convert values to float and replace -9999 nodata values with NaN\n",
    "        values_df['value'] = pd.to_numeric(values_df['value']).replace(-9999, np.nan)\n",
    "        #Remove any records flagged with lower quality\n",
    "        values_df = values_df[values_df['quality_control_level_code'] == '1']\n",
    "    except:\n",
    "        print(\"Unable to fetch %s\" % variablecode)\n",
    "    \n",
    "    return values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snotel_data(gdf,sddt, eddt,var,units='metric'):\n",
    "    '''\n",
    "    gdf - pandas geodataframe of SNOTEL sites\n",
    "    st_dt - start date string 'yyyy-mm-dd'\n",
    "    ed_dt - end date string 'yyyy-mm-dd'\n",
    "    var - snotel variable of interest \n",
    "    units - 'metric' (default) or 'imperial'\n",
    "    '''\n",
    "    stn_data = pd.DataFrame(index=pd.date_range(start=stdt, end=eddt))\n",
    "    network = 'SNOTEL:'    \n",
    "\n",
    "    for sitecode in gdf.code:\n",
    "        try:\n",
    "            data = fetch(sitecode,network+var+'_D', start_date=stdt, end_date=eddt)\n",
    "            #print(data)\n",
    "            #check for nan values\n",
    "            if len(data.value[np.isnan(data.value)]) > 0:\n",
    "                #check if more than 10% of data is missing\n",
    "                if len(data.value[np.isnan(data.value)])/len(data) > .02:\n",
    "                    print('More than 2% of days missing')\n",
    "                    gdf.drop(gdf.loc[gdf['code']==sitecode].index, inplace=True)\n",
    "                    continue\n",
    "            stn_data[sitecode] = data.value\n",
    "            print(data.value)\n",
    "        except:\n",
    "            gdf.drop(gdf.loc[gdf['code']==sitecode].index, inplace=True)     \n",
    "    \n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "    if units == 'metric':\n",
    "        for sitecode in gdf.code:\n",
    "            stn_data[sitecode] = 2.54 * stn_data[sitecode]\n",
    "\n",
    "    return gdf, stn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### run stuff\n",
    "#call the function to get dates\n",
    "stdt, eddt = set_dates(st_dt,ed_dt,date_flag)\n",
    "#print(stdt, eddt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved station locations\n",
      "          code   longitude   latitude               name         elevation_m  \\\n",
      "0  388_OR_SNTL -122.060097  43.590420     Cascade Summit    1554.47998046875   \n",
      "1  529_OR_SNTL -122.568771  43.669170    Holland Meadows  1502.6639404296875   \n",
      "2  710_OR_SNTL -122.212723  43.658871  Railroad Overpass    816.864013671875   \n",
      "3  719_OR_SNTL -122.030632  43.900982      Roaring River   1508.760009765625   \n",
      "4  729_OR_SNTL -122.117577  43.611931   Salt Creek Falls  1286.2559814453125   \n",
      "\n",
      "                      geometry  \n",
      "0  POINT (-122.06010 43.59042)  \n",
      "1  POINT (-122.56877 43.66917)  \n",
      "2  POINT (-122.21272 43.65887)  \n",
      "3  POINT (-122.03063 43.90098)  \n",
      "4  POINT (-122.11758 43.61193)  \n"
     ]
    }
   ],
   "source": [
    "#get snotel stations\n",
    "snotel_gdf = get_snotel_stns()\n",
    "print('Retrieved station locations')\n",
    "print(snotel_gdf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2022-01-01    60\n",
      "2022-01-02    56\n",
      "Name: value, dtype: int64\n",
      "datetime\n",
      "2022-01-01    50\n",
      "2022-01-02    47\n",
      "Name: value, dtype: int64\n",
      "datetime\n",
      "2022-01-01    15\n",
      "2022-01-02    11\n",
      "Name: value, dtype: int64\n",
      "datetime\n",
      "2022-01-01    51\n",
      "2022-01-02    48\n",
      "Name: value, dtype: int64\n",
      "datetime\n",
      "2022-01-01    44\n",
      "2022-01-02    42\n",
      "Name: value, dtype: int64\n",
      "Retrieved station data\n",
      "                      geometry         code\n",
      "0  POINT (-122.06010 43.59042)  388_OR_SNTL\n",
      "1  POINT (-122.56877 43.66917)  529_OR_SNTL\n",
      "2  POINT (-122.21272 43.65887)  710_OR_SNTL\n",
      "3  POINT (-122.03063 43.90098)  719_OR_SNTL\n",
      "4  POINT (-122.11758 43.61193)  729_OR_SNTL\n"
     ]
    }
   ],
   "source": [
    "#get data\n",
    "SNOTELgdf, hs = get_snotel_data(snotel_gdf,stdt,eddt,'SNWD')\n",
    "print('Retrieved station data')\n",
    "#print(SNOTELgdf);\n",
    "cols=['geometry','code']\n",
    "SNOTELgdf_subset=SNOTELgdf[cols];\n",
    "print(SNOTELgdf_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            388_OR_SNTL  395_OR_SNTL  442_OR_SNTL  529_OR_SNTL  545_OR_SNTL  \\\n",
      "2022-01-01       152.40        58.42        73.66       127.00       147.32   \n",
      "2022-01-02       142.24        58.42        73.66       119.38       134.62   \n",
      "\n",
      "            660_OR_SNTL  710_OR_SNTL  719_OR_SNTL  729_OR_SNTL  801_OR_SNTL  \\\n",
      "2022-01-01        81.28        38.10       129.54       111.76       152.40   \n",
      "2022-01-02        81.28        27.94       121.92       106.68       144.78   \n",
      "\n",
      "            1044_OR_SNTL  \n",
      "2022-01-01          50.8  \n",
      "2022-01-02          50.8  \n"
     ]
    }
   ],
   "source": [
    "print(hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=hs.T\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395_OR_SNTL\n"
     ]
    }
   ],
   "source": [
    "print(SNOTELgdf_subset.code[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.4\n"
     ]
    }
   ],
   "source": [
    "print(hs.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowmodelcal]",
   "language": "python",
   "name": "conda-env-snowmodelcal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
